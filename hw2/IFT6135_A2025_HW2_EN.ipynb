{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyJ4Y-50zfCt"
      },
      "source": [
        "# Notes: You will have to:\n",
        "  >1- Make a Copy of this notebook to edit it for your solutions;\n",
        "  >\n",
        "  >2- Upload on Gradescope: The `Colab Notebook edited with your solutions`, and a `pdf Report` with:\n",
        "  >\n",
        "   >>- All plots from experiments\n",
        "   >>- Written interpretations and analyses\n",
        "   >>- Summary tables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpqQj92Jc95l"
      },
      "source": [
        "# Question 1: xLSTM - Extended Long Short-Term Memory and Long-Sequence Generalization [50 points]\n",
        "\n",
        "\n",
        "This question is divided into five parts. Please read carefully and follow all implementation and reporting instructions.\n",
        "\n",
        "**Note:** Detailed instructions is provided in the HW PDF document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xus-ZUq8yphk"
      },
      "source": [
        "## Section: Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5baWuaLdyxun"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.functional import logsigmoid\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Optional, Tuple, Dict\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsh3jCzCy8Cx"
      },
      "source": [
        "## Part 1.1: Exponential Gates [8 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53MBg7yezQbH"
      },
      "outputs": [],
      "source": [
        "class ExponentialGates(nn.Module):\n",
        "    \"\"\"\n",
        "    ExponentialGates module.\n",
        "\n",
        "    Core building block of xLSTM introducing exponential gating for\n",
        "    better gradient flow over long sequences. A stabilizer state (m_t)\n",
        "    ensures numerical stability by tracking maximum gate activations.\n",
        "\n",
        "    The module supports two modes:\n",
        "        - Exponential gating with stabilizer (xLSTM)\n",
        "        - Standard sigmoid gating (for baseline/ablation)\n",
        "\n",
        "    Returns:\n",
        "        new_states: torch.Tensor [4, batch_size, hidden_size]\n",
        "            (h_t, c_t, n_t, m_t)\n",
        "        gates: torch.Tensor [4, batch_size, hidden_size]\n",
        "            (input_gate, forget_gate, cell_input, output_gate)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size: int, use_exponential: bool = True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_size: int\n",
        "                Dimensionality of the hidden representation.\n",
        "            use_exponential: bool\n",
        "                If True, use exponential gating with stabilizer.\n",
        "                If False, use standard sigmoid gating.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.use_exponential = use_exponential\n",
        "\n",
        "        # TODO: define linear projections for the four gates\n",
        "        # Each projection maps hidden_size → hidden_size and corresponds to:\n",
        "        #   - Input gate: input_gate_proj\n",
        "        #   - Forget gate: forget_gate_proj\n",
        "        #   - Cell input (update): cell_input_proj\n",
        "        #   - Output gate: output_gate_proj\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.input_gate_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.forget_gate_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.cell_input_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output_gate_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        # --------------------------------------------------------------------------\n",
        "        # Note:\n",
        "        # The linear layers and the .forward() method below are for Part 1.1 only,\n",
        "        # allowing ExponentialGates to be tested as a standalone module.\n",
        "        # In the full sLSTM/xLSTM architecture, the gate projections are handled\n",
        "        # by the sLSTMLayer; only the pointwise_* methods are used during training.\n",
        "        # --------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    def forward_pointwise_exp(self, Wx, Ry, b, states, constants):\n",
        "        \"\"\"\n",
        "        Exponential gating path (stabilized).\n",
        "\n",
        "        Uses stabilized exponential gates (i'_t, f'_t) computed with the\n",
        "        stabilizer state m_t. Updates the memory (c_t) and normalizer (n_t)\n",
        "        following the equations provided in the handout.\n",
        "\n",
        "        Args:\n",
        "            Wx: torch.Tensor [batch_size, 4 * hidden_size]\n",
        "                Input projections for all gates.\n",
        "            Ry: torch.Tensor [batch_size, 4 * hidden_size]\n",
        "                Recurrent contributions from h_{t-1}.\n",
        "            b: torch.Tensor [1, 4 * hidden_size]\n",
        "                Bias term for all gates.\n",
        "            states: torch.Tensor [4, batch_size, hidden_size]\n",
        "                Previous recurrent states (h_{t-1}, c_{t-1}, n_{t-1}, m_{t-1}).\n",
        "            constants: dict\n",
        "                Placeholder for optional constants (kept for interface consistency).\n",
        "\n",
        "        Returns:\n",
        "            new_states: torch.Tensor [4, batch_size, hidden_size]\n",
        "                Updated states (h_t, c_t, n_t, m_t).\n",
        "            gates: torch.Tensor [4, batch_size, hidden_size]\n",
        "                Gate activations (input, forget, cell_input, output).\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        h_prev, c_prev, n_prev, m_prev = states\n",
        "        # print(\"x:\", Wx.shape, \"h_prev:\", h_prev.shape)\n",
        "        gates = Wx + Ry + b\n",
        "        i_t, f_t, z_t, o_t = gates.chunk(4, dim=-1)\n",
        "\n",
        "        i_t = torch.sigmoid(i_t)\n",
        "        f_t = torch.sigmoid(f_t)\n",
        "        z_t = torch.tanh(z_t)\n",
        "        o_t = torch.sigmoid(o_t)\n",
        "        m_t = torch.maximum(torch.log(f_t + 1e-8) + m_prev,\n",
        "                            torch.log(i_t + 1e-8))\n",
        "\n",
        "        i_t_prime = torch.exp(torch.log(i_t + 1e-8) - m_t)\n",
        "        f_t_prime = torch.exp(torch.log(f_t + 1e-8) + m_prev - m_t)\n",
        "\n",
        "        c_t = f_t_prime * c_prev + i_t_prime * z_t\n",
        "        n_t = f_t_prime * n_prev + i_t_prime\n",
        "\n",
        "        h_t = o_t * (c_t / (n_t + 1e-8)) #torch.tanh(c_t)\n",
        "\n",
        "        new_states = torch.stack([h_t, c_t, n_t, m_t], dim=0)\n",
        "        gates = torch.stack([i_t_prime, f_t_prime, z_t, o_t], dim=0)\n",
        "\n",
        "\n",
        "        return new_states, gates\n",
        "\n",
        "\n",
        "    def forward_pointwise_sigmoid(self, Wx, Ry, b, states, constants):\n",
        "        \"\"\"\n",
        "        Sigmoid gating path (standard LSTM).\n",
        "\n",
        "        Implements the classical LSTM update using sigmoid and tanh gates.\n",
        "        Provided for comparison and ablation studies.\n",
        "\n",
        "        Args:\n",
        "            Wx, Ry, b, states, constants: same as forward_pointwise_exp().\n",
        "\n",
        "        Returns:\n",
        "            new_states: torch.Tensor [4, batch_size, hidden_size]\n",
        "                (h_t, c_t, n_t, m_t) — n_t and m_t act as placeholders here.\n",
        "            gates: torch.Tensor [4, batch_size, hidden_size]\n",
        "                (input_gate, forget_gate, cell_input, output_gate).\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        h_prev, c_prev, n_prev, m_prev = states\n",
        "\n",
        "        gates = Wx + Ry + b\n",
        "        i_t, f_t, z_t, o_t = gates.chunk(4, dim=-1)\n",
        "\n",
        "        i_t = torch.sigmoid(i_t)\n",
        "        f_t = torch.sigmoid(f_t)\n",
        "        z_t = torch.tanh(z_t)\n",
        "        o_t = torch.sigmoid(o_t)\n",
        "\n",
        "        c_t = f_t * c_prev + i_t * z_t\n",
        "        h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        n_t = n_prev\n",
        "        m_t = m_prev\n",
        "\n",
        "        new_states = torch.stack([h_t, c_t, n_t, m_t], dim=0)\n",
        "        gates = torch.stack([i_t, f_t, z_t, o_t], dim=0)\n",
        "\n",
        "        return new_states, gates\n",
        "\n",
        "    def forward(self, x_t, h_prev, states):\n",
        "        \"\"\"\n",
        "        Main forward interface for one timestep.\n",
        "\n",
        "        Steps:\n",
        "            1. Compute linear projections for all gates from x_t.\n",
        "            2. Prepare recurrent contributions from h_prev and add biases.\n",
        "            3. Depending on `use_exponential`, call:\n",
        "                   - forward_pointwise_exp(...)  → stabilized exponential gates\n",
        "                   - forward_pointwise_sigmoid(...) → standard LSTM gates\n",
        "            4. Return the new states and gate activations.\n",
        "\n",
        "        Args:\n",
        "            x_t: torch.Tensor [batch_size, hidden_size]\n",
        "                Input at time step t.\n",
        "            h_prev: torch.Tensor [batch_size, hidden_size]\n",
        "                Previous hidden state h_{t-1}.\n",
        "            states: torch.Tensor [4, batch_size, hidden_size]\n",
        "                Previous states (h, c, n, m).\n",
        "\n",
        "        Returns:\n",
        "            new_states: torch.Tensor [4, batch_size, hidden_size]\n",
        "            gates: torch.Tensor [4, batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        Wx_i = self.input_gate_proj(x_t)\n",
        "        Wx_f = self.forget_gate_proj(x_t)\n",
        "        Wx_z = self.cell_input_proj(x_t)\n",
        "        Wx_o = self.output_gate_proj(x_t)\n",
        "        Wx = torch.cat([Wx_i, Wx_f, Wx_z, Wx_o], dim=-1)\n",
        "\n",
        "        Ry_i = self.input_gate_proj(h_prev)\n",
        "        Ry_f = self.forget_gate_proj(h_prev)\n",
        "        Ry_z = self.cell_input_proj(h_prev)\n",
        "        Ry_o = self.output_gate_proj(h_prev)\n",
        "        Ry = torch.cat([Ry_i, Ry_f, Ry_z, Ry_o], dim=-1)\n",
        "\n",
        "        b = torch.cat([\n",
        "            self.input_gate_proj.bias,\n",
        "            self.forget_gate_proj.bias,\n",
        "            self.cell_input_proj.bias,\n",
        "            self.output_gate_proj.bias\n",
        "        ]).unsqueeze(0)\n",
        "\n",
        "        constants = {}\n",
        "        if self.use_exponential:\n",
        "            new_states, gates = self.forward_pointwise_exp(Wx, Ry, b, states, constants)\n",
        "        else:\n",
        "            new_states, gates = self.forward_pointwise_sigmoid(Wx, Ry, b, states, constants)\n",
        "\n",
        "        return new_states, gates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U4hbPEb0GnC"
      },
      "source": [
        "## Part 1.2 – sLSTM: Scalar Memory Architecture [8 points]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ4aWwgLTr_v"
      },
      "source": [
        "### Part 1.2.1 sLSTMCell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YH_IbYU0Z-r"
      },
      "outputs": [],
      "source": [
        "class sLSTMCell(nn.Module):\n",
        "    \"\"\"\n",
        "    Core scalar-memory LSTM cell (sLSTM).\n",
        "\n",
        "    Implements the scalar-memory recurrence defined in the handout:\n",
        "        c_t = f'_t * c_{t-1} + i'_t * tanh(z_t)\n",
        "        n_t = f'_t * n_{t-1} + i'_t\n",
        "        h_t = o_t * (c_t / n_t)\n",
        "\n",
        "    The exponential gates (i'_t, f'_t) are stabilized using the ExponentialGates\n",
        "    module with the stabilizer state m_t. The cell maintains four internal states\n",
        "    (h_t, c_t, n_t, m_t) and supports exponential or sigmoid gating.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size: int, use_exponential: bool = True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_size: int\n",
        "                Dimensionality of the hidden representation.\n",
        "            use_exponential: bool\n",
        "                If True, use exponential gating with stabilizer (xLSTM).\n",
        "                If False, use standard sigmoid gating (baseline).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.use_exponential = use_exponential\n",
        "\n",
        "        # TODO: define parameters for the sLSTM recurrence\n",
        "        # Include recurrent weights and biases for the four gates.\n",
        "        # A positive forget gate bias helps with stable training.\n",
        "        # pass  # YOUR CODE HERE\n",
        "        # self.W = nn.Linear(input_size, 4 * hidden_size, bias=False)\n",
        "        self.R =  nn.Linear(hidden_size, 4 * hidden_size, bias=False)\n",
        "        self.b = nn.Parameter(torch.zeros(4 * hidden_size))\n",
        "        with torch.no_grad():\n",
        "            # Set positive bias for forget gate (positions 1, 5, 9, ... in chunks of 4)\n",
        "            self.b[1::4] = 1.0  # Forget gate bias\n",
        "        \n",
        "        # Exponential gates module for stabilized gating\n",
        "        self.gates = ExponentialGates(hidden_size, use_exponential)\n",
        "\n",
        "\n",
        "    def forward_sequence(self, x, states, pointwise_forward):\n",
        "        \"\"\"\n",
        "        Performs the internal recurrent computation across time steps.\n",
        "\n",
        "        This method applies the sLSTM update for each element in the input\n",
        "        sequence while maintaining and returning all intermediate states.\n",
        "\n",
        "        Args:\n",
        "            x: torch.Tensor [seq_len, batch_size, 4 * hidden_size]\n",
        "                Sequence of pre-activation inputs for all gates.\n",
        "            states: torch.Tensor [4, batch_size, hidden_size]\n",
        "                Previous recurrent states (h, c, n, m).\n",
        "            pointwise_forward: Callable\n",
        "                Function that computes a single time-step update.\n",
        "\n",
        "        Returns:\n",
        "            states_all: torch.Tensor [4, seq_len + 1, batch_size, hidden_size]\n",
        "                All intermediate states, including the initial one.\n",
        "            final_state: torch.Tensor [4, batch_size, hidden_size]\n",
        "                Final recurrent state after the last time step.\n",
        "            gates: torch.Tensor [seq_len, 4, batch_size, hidden_size]\n",
        "                Gate activations for each time step.\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        seq_len, batch_size, _ = x.shape\n",
        "\n",
        "        # Store all states (including initial)\n",
        "        states_all = [states]\n",
        "        gates_all = []\n",
        "\n",
        "        # Iterate over each time step\n",
        "        for t in range(seq_len):\n",
        "            h_prev = states[0]\n",
        "\n",
        "            # Compute recurrent contribution Ry_t\n",
        "            Ry_t = self.R(h_prev)\n",
        "\n",
        "            # Compute new states and gates\n",
        "            new_states, gates_t = pointwise_forward(\n",
        "                Wx=x[t],          # input projection for this timestep\n",
        "                Ry=Ry_t,          # recurrent projection\n",
        "                b=self.b,         # bias term\n",
        "                states=states,    # previous states (h, c, n, m)\n",
        "                constants=None\n",
        "            )\n",
        "\n",
        "            # Save results\n",
        "            states_all.append(new_states)\n",
        "            gates_all.append(gates_t)\n",
        "\n",
        "            # Update recurrent state for next timestep\n",
        "            states = new_states\n",
        "\n",
        "        # Stack along time dimension\n",
        "        states_all = torch.stack(states_all, dim=1)      # [4, seq_len + 1, batch_size, hidden_size]\n",
        "        gates_all = torch.stack(gates_all, dim=0)        # [seq_len, 4, batch_size, hidden_size]\n",
        "\n",
        "        final_state = states\n",
        "        return states_all, final_state, gates_all\n",
        "\n",
        "    def forward(self, x, state=None):\n",
        "        \"\"\"\n",
        "        Computes the sLSTM cell output for an entire input sequence.\n",
        "\n",
        "        This is the public interface used by higher-level modules (e.g., sLSTMLayer).\n",
        "        It handles initial state setup and delegates the temporal computation\n",
        "        to `forward_sequence`.\n",
        "\n",
        "        Args:\n",
        "            x: torch.Tensor [batch_size, seq_len, 4 * hidden_size]\n",
        "                Concatenated gate projections for the input sequence.\n",
        "            state: torch.Tensor [4, batch_size, hidden_size], optional\n",
        "                Initial recurrent states (h, c, n, m). Defaults to zeros.\n",
        "\n",
        "        Returns:\n",
        "            output: torch.Tensor [batch_size, seq_len, hidden_size]\n",
        "                Sequence of hidden outputs (h_t).\n",
        "            final_state: torch.Tensor [4, batch_size, hidden_size]\n",
        "                Final recurrent states after processing the sequence.\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        x = x.transpose(0, 1)\n",
        "\n",
        "        if state is None:\n",
        "            h0 = x.new_zeros(batch_size, self.hidden_size)\n",
        "            c0 = x.new_zeros(batch_size, self.hidden_size)\n",
        "            n0 = x.new_zeros(batch_size, self.hidden_size)\n",
        "            m0 = x.new_zeros(batch_size, self.hidden_size)\n",
        "            state = torch.stack([h0, c0, n0, m0], dim=0)\n",
        "\n",
        "        if self.use_exponential:\n",
        "            pointwise_forward = self.gates.forward_pointwise_exp\n",
        "        else:\n",
        "            pointwise_forward = self.gates.forward_pointwise_sigmoid\n",
        "\n",
        "        states_all, final_state, gates = self.forward_sequence(x, state, pointwise_forward)\n",
        "\n",
        "        output = states_all[0]  # [seq_len + 1, batch_size, hidden_size]\n",
        "        output = output[1:].transpose(0, 1)  # remove initial state, [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        return output, final_state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pat-pI2B1PeU"
      },
      "source": [
        "### Part 1.2.2 – sLSTMLayer: High-Level Sequence Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mVRmTlm1O6g"
      },
      "outputs": [],
      "source": [
        "class sLSTMLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    High-level sequence processor built on top of sLSTMCell.\n",
        "\n",
        "    Applies the sLSTM recurrence across time for input sequences of shape [B, T, H]:\n",
        "        h_t, (h, c, n, m) = sLSTMCell(x_t, h_{t-1}, states)\n",
        "    Returns the full hidden sequence and final states.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size: int, dropout_prob: float=0.1, use_exponential: bool = True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_size: int\n",
        "                Dimensionality of the hidden representation.\n",
        "            dropout_prob: float\n",
        "                Dropout probability applied to the output sequence.\n",
        "            use_exponential: bool\n",
        "                If True, use exponential gating (xLSTM mode).\n",
        "                If False, use standard sigmoid gating (baseline).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        # Gate projections\n",
        "        # Each projection maps hidden_size → hidden_size and corresponds to:\n",
        "        #   - Input gate: igate\n",
        "        #   - Forget gate: fgate\n",
        "        #   - Cell input (update): zgate\n",
        "        #   - Output gate: ogate\n",
        "        # pass # YOUR CODE HERE\n",
        "        self.igate = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fgate = nn.Linear(hidden_size, hidden_size)\n",
        "        self.zgate = nn.Linear(hidden_size, hidden_size)\n",
        "        self.ogate = nn.Linear(hidden_size, hidden_size)\n",
        "        self.cell = sLSTMCell(hidden_size, use_exponential)\n",
        "        pass # YOUR CODE HERE\n",
        "\n",
        "\n",
        "    def forward(self, x, initial_state=None):\n",
        "        \"\"\"\n",
        "        Forward pass of sLSTM layer for batch processing.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        Returns:\n",
        "            output: Output tensor [batch_size, seq_len, hidden_size]\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        \n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        # Compute gate projections\n",
        "        Wx_i = self.igate(x)\n",
        "        Wx_f = self.fgate(x)\n",
        "        Wx_z = self.zgate(x)\n",
        "        Wx_o = self.ogate(x)\n",
        "        Wx = torch.cat([Wx_i, Wx_f, Wx_z, Wx_o], dim=-1)\n",
        "        # Forward through sLSTMCell\n",
        "        \n",
        "        # x_gated = x_gated.transpose(0, 1)  # [seq_len, batch_size, 4 * hidden_size]\n",
        "        \n",
        "        # # Process sequence through sLSTMCell\n",
        "        # output_seq, final_states = self.cell(x_gated, initial_state)\n",
        "        \n",
        "        # # Transpose output back to [batch_size, seq_len, hidden_size]\n",
        "        # output = output_seq.transpose(0, 1)  # [batch_size, seq_len, hidden_size]\n",
        "        \n",
        "        # # Apply dropout to the output sequence\n",
        "        # output = self.dropout(output)\n",
        "\n",
        "\n",
        "        output, final_state = self.cell(Wx, initial_state)\n",
        "        output = self.dropout(output)\n",
        "        return output, final_state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgssRWdV1osA"
      },
      "source": [
        "## **Part 1.3 – xLSTM Block and Stack [8 points]**\n",
        "\n",
        "In this section, we assemble full **xLSTM layers** by combining the previously implemented components into Transformer-style residual blocks.\n",
        "\n",
        "The code below already provides:\n",
        "- **LayerNorm** with residual weighting — ensures numerical stability during deep stacking. *(No edits required.)*\n",
        "- **GatedMLP** using GeLU activation and a projection factor of 4/3. *(No edits required.)*\n",
        "\n",
        "You will complete:\n",
        "- **xLSTMBlock** — one residual block that wraps:\n",
        "  1. LayerNorm → sLSTM layer → first residual connection  \n",
        "  2. LayerNorm → GatedMLP → second residual connection  \n",
        "  The block should return the final tensor after both residuals.\n",
        "\n",
        "- **xLSTM** — a stack of multiple xLSTMBlocks that processes entire sequences in parallel.  \n",
        "  It should loop over the configured number of layers and apply each block sequentially.\n",
        "\n",
        "Follow the structure and equations described in the handout.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc9idwNc6hjn"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization with residual weight mechanism (important for xLSTM stability).\"\"\"\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.zeros(hidden_size))  # Start with zeros!\n",
        "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Use residual weight: 1.0 + weight (important for xLSTM!)\n",
        "        weight_proxy = 1.0 + self.weight\n",
        "        return torch.nn.functional.layer_norm(x, normalized_shape=(x.shape[-1],),\n",
        "                                           weight=weight_proxy, bias=self.bias, eps=self.eps)\n",
        "\n",
        "\n",
        "class GatedMLP(nn.Module):\n",
        "    \"\"\"Gated MLP with GeLU activation and projection factor 4/3.\"\"\"\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.projection_factor = 4 / 3\n",
        "        self.inner_size = int(hidden_size * self.projection_factor)\n",
        "\n",
        "        self.up_proj = nn.Linear(hidden_size, self.inner_size)\n",
        "        self.down_proj = nn.Linear(self.inner_size, hidden_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.down_proj(torch.nn.functional.gelu(self.up_proj(x)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeS6sfWl1uNy"
      },
      "outputs": [],
      "source": [
        "class xLSTMBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    One residual block of the xLSTM architecture.\n",
        "\n",
        "    Each block follows:\n",
        "        h₁ = sLSTMLayer(LayerNorm(x))\n",
        "        x₁ = x + h₁\n",
        "        h₂ = GeLU(W_up * LayerNorm(x₁))\n",
        "        x₂ = x₁ + W_down * h₂\n",
        "\n",
        "    Combines recurrent memory updates (via sLSTM) and gated feed-forward\n",
        "    processing within dual residual connections.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hidden_size: int, dropout_prob: float, use_exponential: bool = True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_size: int\n",
        "                Dimensionality of the hidden representation.\n",
        "            use_exponential: bool\n",
        "                Whether to use exponential gating (xLSTM) or sigmoid gating (baseline).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        pass  # YOUR CODE HERE\n",
        "        self.layer_norm = LayerNorm(hidden_size)\n",
        "        self.slstm = sLSTMLayer(hidden_size, use_exponential)\n",
        "        self.mlp_norm = LayerNorm(hidden_size)  # Separate LayerNorm for MLP\n",
        "        self.gated_mlp = GatedMLP(hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of xLSTM block for batch processing.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        Returns:\n",
        "            output: Output tensor [batch_size, seq_len, hidden_size]\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        # print(f\"x.shape before transpose: {x.shape}\")\n",
        "\n",
        "        if x.dim() == 3 and x.shape[1] == self.hidden_size and x.shape[2] != self.hidden_size:\n",
        "            x = x.transpose(1, 2)\n",
        "\n",
        "            # likely shape is [B, H, T] — fix it\n",
        "            # x = x.transpose(1, 2)\n",
        "            # Now shape = [B, T, H]\n",
        "\n",
        "        x_norm = self.layer_norm(x)\n",
        "        h1, _ = self.slstm(x_norm)\n",
        "        x1 = x + h1\n",
        "        x1_norm = self.mlp_norm(x1)\n",
        "        h2 = self.gated_mlp(x1_norm)\n",
        "        x2 = x1 + h2\n",
        "        return x2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOAx14s81zEy"
      },
      "outputs": [],
      "source": [
        "class xLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Full xLSTM stack of L residual blocks.\n",
        "\n",
        "    Applies the recurrence:\n",
        "        x ← xLSTMBlock₁(x)\n",
        "        ...\n",
        "        x ← xLSTMBlock_L(x)\n",
        "\n",
        "    Args:\n",
        "        d: Hidden dimension.\n",
        "        num_layers: Number of stacked xLSTM blocks.\n",
        "        dropout_prob: Dropout probability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d: int, num_layers: int, dropout_prob: float = 0.1, use_exponential: bool = True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_size: int\n",
        "                Dimensionality of the hidden representation.\n",
        "            num_layers: int\n",
        "                Number of stacked xLSTM blocks.\n",
        "            use_exponential: bool\n",
        "                If True, use exponential gating (xLSTM mode).\n",
        "                If False, use standard sigmoid gating (baseline).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # TODO: create list of xLSTMBlock modules\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.input_proj = nn.LazyLinear(d)\n",
        "        self.layers = nn.ModuleList([\n",
        "            xLSTMBlock(d, dropout_prob, use_exponential)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.output_proj = None  # will be created dynamically\n",
        "        self.hidden_size = d\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through all blocks with true batch processing.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        Returns:\n",
        "            output: Final output [batch_size, seq_len, hidden_size]\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        x = self.input_proj(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Take the last timestep\n",
        "        x = x[:, -1, :]   # [B, H]\n",
        "\n",
        "        # Lazy init: create output projection on first forward\n",
        "        if self.output_proj is None:\n",
        "            num_classes = x.shape[-1]  # or another dimension if provided\n",
        "            self.output_proj = nn.Linear(self.hidden_size, num_classes).to(x.device)\n",
        "\n",
        "        out = self.output_proj(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcj8wiQo2aMR"
      },
      "source": [
        "## Part 1.4 –  xLSTM Training on the Parity Task [6 points]\n",
        "\n",
        "In this part, you will train and evaluate your **xLSTM implementation** on a synthetic *parity task* that tests the model’s ability to capture **long-range dependencies**.\n",
        "\n",
        "Several helper components are provided to make experimentation easier:\n",
        "\n",
        "- **ParityDataset** – Generates binary sequences and corresponding parity labels for both training and testing. *(No modifications required.)*  \n",
        "- **ModelFactory** – Creates and configures different model types (xLSTM-Exp, xLSTM-Sigmoid, and Vanilla LSTM). *(No modifications required.)*  \n",
        "- **ModelTrainer** – Implements batching, optimization, and evaluation.  \n",
        "  ➜ *You will complete this section.*  \n",
        "- **ExperimentRunner** – Manages the full training and evaluation pipeline, connecting all components together. *(No modifications required.)*\n",
        "\n",
        "Your goal in this part is to **complete the missing code in `ModelTrainer`** and verify that your models from previous parts can successfully learn and generalize on the parity dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmwaj1XU25nf"
      },
      "source": [
        "### Parity Dataset (No Modifications Required)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcdaWCGS2d8p"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ParityDataset: Complete implementation provided - handles the generation of the parity dataset.\n",
        "# No modifications required.\n",
        "class ParityDataset:\n",
        "    \"\"\"Parity dataset with variable-length training and generalization testing.\"\"\"\n",
        "\n",
        "    def __init__(self, max_length: int, num_samples: int = 1000,\n",
        "                 variable_length: bool = True, test_range: tuple = None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_length: Maximum training length (for variable-length sequences).\n",
        "            num_samples: Number of samples to generate.\n",
        "            variable_length: Whether to randomly sample sequence lengths (for training/test).\n",
        "            test_range: Tuple (min_len, max_len) for generalization test (e.g., (40, 256)).\n",
        "        \"\"\"\n",
        "        self.max_length = max_length\n",
        "        self.num_samples = num_samples\n",
        "        self.variable_length = variable_length\n",
        "        self.test_range = test_range\n",
        "\n",
        "    def generate_sequence(self, length: int) -> Tuple[torch.Tensor, int]:\n",
        "        seq = torch.randint(0, 2, (length,))\n",
        "        parity = seq.sum().item() % 2\n",
        "        return seq.float(), parity\n",
        "\n",
        "    def create_dataset(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Create padded dataset with mask for variable-length sequences.\"\"\"\n",
        "        sequences, labels, lengths = [], [], []\n",
        "\n",
        "        for _ in range(self.num_samples):\n",
        "            if self.test_range:\n",
        "                # Test mode: sample random length from generalization range\n",
        "                length = np.random.randint(self.test_range[0], self.test_range[1] + 1)\n",
        "            elif self.variable_length:\n",
        "                # Training or in-distribution test: sample 1–max_length\n",
        "                length = np.random.randint(1, self.max_length + 1)\n",
        "            else:\n",
        "                # Fixed-length case\n",
        "                length = self.max_length\n",
        "\n",
        "            seq, label = self.generate_sequence(length)\n",
        "            sequences.append(seq)\n",
        "            labels.append(label)\n",
        "            lengths.append(length)\n",
        "\n",
        "        max_len = max(lengths)\n",
        "        padded_sequences = torch.zeros(self.num_samples, max_len)\n",
        "        mask = torch.zeros_like(padded_sequences)\n",
        "\n",
        "        for i, seq in enumerate(sequences):\n",
        "            padded_sequences[i, :len(seq)] = seq\n",
        "            mask[i, :len(seq)] = 1  # mark valid positions\n",
        "\n",
        "        return padded_sequences, torch.tensor(labels), mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCsgKu292tq-"
      },
      "source": [
        "### Model Factory (No Modifications Required)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlUdH0Fn3Mkv"
      },
      "outputs": [],
      "source": [
        "# ModelFactory: Complete implementation provided - handles the creation of different model types.\n",
        "# including model creation. No modifications required.\n",
        "class ModelFactory:\n",
        "    \"\"\"Factory for creating different model types.\"\"\"\n",
        "\n",
        "    def __init__(self, config: dict):\n",
        "        self.config = config\n",
        "\n",
        "    def create_xlstm_exp(self) -> xLSTM:\n",
        "        \"\"\"Create xLSTM with exponential gates.\"\"\"\n",
        "        model = xLSTM(self.config['hidden_size'], self.config['num_layers'], use_exponential=True)\n",
        "        model.input_proj = nn.Linear(1, self.config['hidden_size'])  # Project binary input to hidden_size\n",
        "        model.classifier = nn.Linear(self.config['hidden_size'], 2)\n",
        "        return model\n",
        "\n",
        "    def create_xlstm_sigmoid(self) -> xLSTM:\n",
        "        \"\"\"Create xLSTM with sigmoid gates.\"\"\"\n",
        "        model = xLSTM(self.config['hidden_size'], self.config['num_layers'], use_exponential=False)\n",
        "        model.input_proj = nn.Linear(1, self.config['hidden_size'])  # Project binary input to hidden_size\n",
        "        model.classifier = nn.Linear(self.config['hidden_size'], 2)\n",
        "        return model\n",
        "\n",
        "    def create_vanilla_lstm(self) -> nn.Module:\n",
        "        \"\"\"Create vanilla LSTM baseline.\"\"\"\n",
        "        model = nn.LSTM(self.config['hidden_size'], self.config['hidden_size'],\n",
        "                       self.config['num_layers'], batch_first=True)\n",
        "        model.input_proj = nn.Linear(1, self.config['hidden_size'])  # Project binary input to hidden_size\n",
        "        model.classifier = nn.Linear(self.config['hidden_size'], 2)\n",
        "        model.hidden_size = self.config['hidden_size']  # Add for compatibility\n",
        "        return model\n",
        "\n",
        "    def create_all_models(self) -> dict:\n",
        "        \"\"\"Create all models for comparison.\"\"\"\n",
        "        return {\n",
        "            'xLSTM (Exponential)': self.create_xlstm_exp(),\n",
        "            'xLSTM (Sigmoid)': self.create_xlstm_sigmoid(),\n",
        "            'Vanilla LSTM': self.create_vanilla_lstm()\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdohsgZT3W83"
      },
      "source": [
        "### Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhCfQ_br32hT"
      },
      "outputs": [],
      "source": [
        "from pyexpat import model\n",
        "\n",
        "\n",
        "class ModelTrainer:\n",
        "    \"\"\"Handles training and evaluation of models (with masking support).\"\"\"\n",
        "\n",
        "    def __init__(self, batch_size: int = 256, lr: float = 0.001):\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "    def train_model(self, model: nn.Module, train_data: tuple, epochs: int = 10):\n",
        "        \"\"\"\n",
        "        Generic training loop supporting padding masks.\n",
        "\n",
        "        Expects:\n",
        "            train_data = (sequences, labels, masks)\n",
        "        \"\"\"\n",
        "        sequences, labels, masks = train_data\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr, weight_decay=0.1)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        model = model.to(self.device)\n",
        "        sequences, labels, masks = (\n",
        "            sequences.to(self.device),\n",
        "            labels.to(self.device),\n",
        "            masks.to(self.device),\n",
        "        )\n",
        "\n",
        "        losses_per_epoch = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss, correct = 0.0, 0\n",
        "\n",
        "            for batch_start in range(0, len(sequences), self.batch_size):\n",
        "                batch_end = min(batch_start + self.batch_size, len(sequences))\n",
        "                x = sequences[batch_start:batch_end]\n",
        "                y = labels[batch_start:batch_end]\n",
        "                m = masks[batch_start:batch_end]\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                if hasattr(model, \"input_proj\") and hasattr(model, \"classifier\"):\n",
        "                    if x.ndim == 2:\n",
        "                        x = x.unsqueeze(-1)\n",
        "\n",
        "                    # Try direct call first\n",
        "                    try:\n",
        "                        out = model(x)\n",
        "                    except RuntimeError as e:\n",
        "                        if \"input.size(-1)\" in str(e):  # means input needs projection\n",
        "                            x_proj = model.input_proj(x)\n",
        "                            out = model(x_proj)\n",
        "                        else:\n",
        "                            raise e\n",
        "\n",
        "                    # ✅ Handle both tensor and tuple outputs (e.g., nn.LSTM returns tuple)\n",
        "                    if isinstance(out, tuple):\n",
        "                        out = out[0]  # extract the sequence output\n",
        "\n",
        "                    # Handle both [B, T, H] and [B, H]\n",
        "                    if out.ndim == 3:\n",
        "                        out = out[:, -1, :]\n",
        "\n",
        "                    logits = model.classifier(out)\n",
        "\n",
        "                else:\n",
        "                    if x.ndim == 2:\n",
        "                        x = x.unsqueeze(-1)\n",
        "                    logits = model(x)\n",
        "\n",
        "                loss = criterion(logits, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                correct += (logits.argmax(dim=1) == y).sum().item()\n",
        "\n",
        "            avg_loss = total_loss / (len(sequences) // self.batch_size + 1)\n",
        "            acc = correct / len(sequences)\n",
        "            losses_per_epoch.append(avg_loss)\n",
        "            print(f\"Epoch {epoch+1}/{epochs} — Loss: {avg_loss:.4f}, Acc: {acc:.4f}\")\n",
        "\n",
        "        return losses_per_epoch\n",
        "\n",
        "    def evaluate_model(self, model: nn.Module, test_data: tuple) -> float:\n",
        "        \"\"\"\n",
        "        Evaluation loop with padding mask support.\n",
        "        \"\"\"\n",
        "        sequences, labels, masks = test_data\n",
        "        model = model.to(self.device)\n",
        "        sequences, labels, masks = (\n",
        "            sequences.to(self.device),\n",
        "            labels.to(self.device),\n",
        "            masks.to(self.device),\n",
        "        )\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_start in range(0, len(sequences), self.batch_size):\n",
        "                batch_end = min(batch_start + self.batch_size, len(sequences))\n",
        "                x = sequences[batch_start:batch_end]\n",
        "                y = labels[batch_start:batch_end]\n",
        "                m = masks[batch_start:batch_end]\n",
        "\n",
        "                # Forward pass — implement your model call here\n",
        "                # Example: logits = model(x, m)\n",
        "                # ---------------------------------\n",
        "                # YOUR CODE HERE\n",
        "                # ---------------------------------\n",
        "                if hasattr(model, \"input_proj\") and hasattr(model, \"classifier\"):\n",
        "                    if x.ndim == 2:\n",
        "                        x = x.unsqueeze(-1)\n",
        "\n",
        "                    # Try direct call first\n",
        "                    try:\n",
        "                        out = model(x)\n",
        "                    except RuntimeError as e:\n",
        "                        if \"input.size(-1)\" in str(e):  # means input needs projection\n",
        "                            x_proj = model.input_proj(x)\n",
        "                            out = model(x_proj)\n",
        "                        else:\n",
        "                            raise e\n",
        "\n",
        "                    # ✅ Handle both tensor and tuple outputs (e.g., nn.LSTM returns tuple)\n",
        "                    if isinstance(out, tuple):\n",
        "                        out = out[0]  # extract the sequence output\n",
        "\n",
        "                    # Handle both [B, T, H] and [B, H]\n",
        "                    if out.ndim == 3:\n",
        "                        out = out[:, -1, :]\n",
        "\n",
        "                    logits = model.classifier(out)\n",
        "\n",
        "                else:\n",
        "                    if x.ndim == 2:\n",
        "                        x = x.unsqueeze(-1)\n",
        "                    logits = model(x)\n",
        "                correct += (logits.argmax(dim=1) == y).sum().item()\n",
        "\n",
        "        return correct / len(sequences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98WSB8CY4N4O"
      },
      "source": [
        "### Experiment Runner (No Modifications Required)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu0nF9Ux4Ukc"
      },
      "outputs": [],
      "source": [
        "# ExperimentRunner: Complete implementation provided - handles the full experiment pipeline\n",
        "# including model testing, training, and evaluation. No modifications required.\n",
        "class ExperimentRunner:\n",
        "    \"\"\"Runs the complete experiment pipeline.\"\"\"\n",
        "\n",
        "    def __init__(self, config: dict):\n",
        "        self.config = config\n",
        "        self.model_factory = ModelFactory(config)\n",
        "        self.trainer = ModelTrainer(\n",
        "            batch_size=config.get('batch_size', 256),\n",
        "            lr=config.get('learning_rate', 1e-3)\n",
        "        )\n",
        "\n",
        "    def test_exponential_gates(self):\n",
        "        \"\"\"Test Part 1.1: ExponentialGates implementation.\"\"\"\n",
        "        print(\"Testing ExponentialGates...\")\n",
        "\n",
        "        # Create gates\n",
        "        gates_exp = ExponentialGates(self.config['hidden_size'], use_exponential=True)\n",
        "        gates_sigmoid = ExponentialGates(self.config['hidden_size'], use_exponential=False)\n",
        "\n",
        "        # Test data\n",
        "        batch_size = 4\n",
        "        x_t = torch.randn(batch_size, self.config['hidden_size'])\n",
        "        h_prev = torch.randn(batch_size, self.config['hidden_size'])\n",
        "        states = torch.randn(4, batch_size, self.config['hidden_size'])\n",
        "\n",
        "        # Test exponential gates\n",
        "        new_states_exp, gates_exp_vals = gates_exp(x_t, h_prev, states)\n",
        "        print(f\"✅ Exponential gates output shape: {new_states_exp.shape}\")\n",
        "\n",
        "        # Test sigmoid gates\n",
        "        new_states_sigmoid, gates_sigmoid_vals = gates_sigmoid(x_t, h_prev, states)\n",
        "        print(f\"✅ Sigmoid gates output shape: {new_states_sigmoid.shape}\")\n",
        "\n",
        "        print(\"✅ Part 1.1: ExponentialGates working correctly!\")\n",
        "\n",
        "    def test_slstm_cell(self):\n",
        "        \"\"\"Test Part 1.2: sLSTMCell implementation.\"\"\"\n",
        "        print(\"Testing sLSTMCell...\")\n",
        "\n",
        "        # Create sLSTM cell\n",
        "        slstm = sLSTMCell(self.config['hidden_size'], use_exponential=True)\n",
        "\n",
        "        # Test data\n",
        "        batch_size = 4\n",
        "        seq_len = 10\n",
        "        x = torch.randn(batch_size, seq_len, 4 * self.config['hidden_size'])  # Concatenated gates\n",
        "\n",
        "        # Test forward pass\n",
        "        output, final_state = slstm(x)\n",
        "        print(f\"✅ sLSTM output shape: {output.shape}\")\n",
        "        print(f\"✅ sLSTM final state shape: {final_state.shape}\")\n",
        "\n",
        "        print(\"✅ Part 1.2: sLSTMCell working correctly!\")\n",
        "\n",
        "    def test_xlstm_architecture(self):\n",
        "        \"\"\"Test Part 1.3: xLSTM Block and Stack.\"\"\"\n",
        "        print(\"Testing xLSTM architecture...\")\n",
        "\n",
        "        # Create xLSTM\n",
        "        xlstm = xLSTM(self.config['hidden_size'], self.config['num_layers'], use_exponential=True)\n",
        "\n",
        "        # Test data\n",
        "        batch_size = 4\n",
        "        seq_len = 10\n",
        "        x = torch.randn(batch_size, seq_len, self.config['hidden_size'])\n",
        "\n",
        "        # Test forward pass (batch processing)\n",
        "        output = xlstm(x)\n",
        "        print(f\"✅ xLSTM output shape: {output.shape}\")\n",
        "\n",
        "        print(\"✅ Part 1.3: xLSTM architecture working correctly!\")\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 2. Main Experiment Flow\n",
        "    # -------------------------------------------------------------------------\n",
        "    def run_experiment(self):\n",
        "        \"\"\"Run complete training and evaluation experiment.\"\"\"\n",
        "        print(\"Running complete experiment...\")\n",
        "\n",
        "        # === Datasets ===\n",
        "        print(\"Preparing datasets...\")\n",
        "        # Training: variable 1–40\n",
        "        train_dataset = ParityDataset(\n",
        "            max_length=self.config['train_length'],\n",
        "            num_samples=self.config['num_samples'],\n",
        "            variable_length=True\n",
        "        )\n",
        "        train_data = train_dataset.create_dataset()\n",
        "\n",
        "        # IID test: 1–40\n",
        "        test_id_dataset = ParityDataset(\n",
        "            max_length=self.config['train_length'],\n",
        "            num_samples=1000,\n",
        "            variable_length=True\n",
        "        )\n",
        "        test_id_data = test_id_dataset.create_dataset()\n",
        "\n",
        "        # Generalization test: 40–256\n",
        "        test_ood_dataset = ParityDataset(\n",
        "            max_length=self.config['test_max_length'],\n",
        "            num_samples=1000,\n",
        "            variable_length=False,\n",
        "            test_range=(40, 256)\n",
        "        )\n",
        "        test_ood_data = test_ood_dataset.create_dataset()\n",
        "\n",
        "        # === Models ===\n",
        "        models = self.model_factory.create_all_models()\n",
        "\n",
        "        # === Training ===\n",
        "        loss_histories = {}\n",
        "        for name, model in models.items():\n",
        "            print(f\"\\nTraining {name}...\")\n",
        "            loss_history = self.trainer.train_model(model, train_data, self.config['epochs'])\n",
        "            loss_histories[name] = loss_history\n",
        "\n",
        "        # === Evaluation & Analysis ===\n",
        "        self.analyze_results(models, loss_histories, test_id_data, test_ood_data)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 3. Unified Analyze Function\n",
        "    # -------------------------------------------------------------------------\n",
        "    def analyze_results(self, models: dict, loss_histories: dict,\n",
        "                        test_id_data: tuple, test_ood_data: tuple):\n",
        "        \"\"\"Evaluate all models and generate IID + generalization plots and table.\"\"\"\n",
        "        print(\"\\n🔍 Analyzing results...\")\n",
        "\n",
        "        # Evaluate all models\n",
        "        results = {}\n",
        "        for name, model in models.items():\n",
        "            print(f\"\\nEvaluating {name}...\")\n",
        "            id_acc = self.trainer.evaluate_model(model, test_id_data)\n",
        "            ood_acc = self.trainer.evaluate_model(model, test_ood_data)\n",
        "            results[name] = (id_acc, ood_acc)\n",
        "            print(f\"✅ {name}: In-Dist={id_acc:.3f}, Generalization={ood_acc:.3f}\")\n",
        "\n",
        "        # === Plot all results ===\n",
        "        self.plot_training_loss(loss_histories)\n",
        "        self.plot_in_distribution_accuracy(results)\n",
        "        self.plot_generalization_accuracy(results)\n",
        "        self.create_results_table(results)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # 4. Plots & Summary\n",
        "    # -------------------------------------------------------------------------\n",
        "    def plot_training_loss(self, loss_histories: dict):\n",
        "        \"\"\"Plot training loss over epochs for all models.\"\"\"\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for name, losses in loss_histories.items():\n",
        "            plt.plot(range(1, len(losses)+1), losses, marker='o', label=name, markersize=3)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Training Loss')\n",
        "        plt.title('Training Loss Over Time')\n",
        "        plt.legend()\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_in_distribution_accuracy(self, results: dict):\n",
        "        \"\"\"Plot in-distribution (1–40) test accuracy for all models.\"\"\"\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        models = list(results.keys())\n",
        "        id_accs = [results[m][0] for m in models]\n",
        "        plt.bar(models, id_accs, color='skyblue')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.ylim(0, 1)\n",
        "        plt.title('In-Distribution Accuracy (1–40)')\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_generalization_accuracy(self, results: dict):\n",
        "        \"\"\"Plot generalization (40–256) accuracy for all models.\"\"\"\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        models = list(results.keys())\n",
        "        ood_accs = [results[m][1] for m in models]\n",
        "        plt.bar(models, ood_accs, color='lightcoral')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.ylim(0, 1)\n",
        "        plt.title('Generalization Accuracy (40–256)')\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def create_results_table(self, results: dict):\n",
        "        \"\"\"Print results summary table.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"{'Model':<25}{'In-Distribution (1–40)':<20}{'Generalization (40–256)':<20}\")\n",
        "        print(\"-\"*70)\n",
        "        for name, (id_acc, ood_acc) in results.items():\n",
        "            print(f\"{name:<25}{id_acc:<20.3f}{ood_acc:<20.3f}\")\n",
        "        print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0Nb-7nn5Pf4"
      },
      "source": [
        "## Part 1.5 Result and Analysis [20 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWdL4BGS5b3X"
      },
      "source": [
        "### Training tips\n",
        "When getting started, try training on a small sample — for example, use num_samples = batch_size (e.g., 64 samples) — just to confirm that your model runs without errors and that the loss decreases. Once things look stable, you can increase the number of epochs and data samples for a full training run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Envn50MK5hxP"
      },
      "outputs": [],
      "source": [
        "print(\"🚀 xLSTM Assignment Implementation\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# GPU availability check\n",
        "print(f\"\\n🖥️  GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "print()\n",
        "config = {\n",
        "    'hidden_size': 64,\n",
        "    'num_layers': 2,\n",
        "    'train_length': 40,        # variable-length 1–40\n",
        "    'test_max_length': 256,    # generalization test 40–256\n",
        "    'num_samples': 10000,     # More data for better convergence\n",
        "    'epochs': 20,\n",
        "    'batch_size': 256,\n",
        "    'learning_rate': 1e-3,\n",
        "    'weight_decay': 0.1,     # Add weight decay!\n",
        "}\n",
        "print(f\"Configuration: {config}\")\n",
        "# Create experiment runner\n",
        "experiment = ExperimentRunner(config)\n",
        "# Part 1.1: Test ExponentialGates\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PART 1.1: Testing ExponentialGates\")\n",
        "print(\"=\"*50)\n",
        "experiment.test_exponential_gates()\n",
        "# Part 1.2: Test sLSTMCell\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PART 1.2: Testing sLSTMCell\")\n",
        "print(\"=\"*50)\n",
        "experiment.test_slstm_cell()\n",
        "# Part 1.3: Test xLSTM Architecture\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PART 1.3: Testing xLSTM Architecture\")\n",
        "print(\"=\"*50)\n",
        "experiment.test_xlstm_architecture()\n",
        "# Part 1.4 & 1.5: Run Complete Experiment\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PART 1.4 & 1.5: Complete Experiment\")\n",
        "print(\"=\"*50)\n",
        "experiment.run_experiment()\n",
        "print(\"\\n✅ HW1 completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNWoiYrUTh5q"
      },
      "source": [
        "# Question 2: Building a Modern Transformer for Modular Arithmetic [50 points]\n",
        "\n",
        "In this question, you will implement a state-of-the-art decoder-only transformer architecture from scratch using PyTorch. Your model will learn to perform modular arithmetic operations. Through careful implementation and systematic experimentation, you will gain deep understanding of modern architectural components including RMSNorm, SwiGLU activations, rotary position embeddings (RoPE), and grouped-query attention (GQA). This assignment emphasizes both implementation rigor and experimental methodology."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJdB1Yv4T25Z"
      },
      "source": [
        "## Section 0: Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ocuxjx05TKdn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Tuple, List, Optional, Dict\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8hJ9JFbeuW1"
      },
      "source": [
        "## Section 1: Core Component Implementations (30 points total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgDzUKUNUK_n"
      },
      "source": [
        "### 1.1 RMSNorm: Root Mean Square Normalization [3 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZLkQNPWULZe"
      },
      "outputs": [],
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Root Mean Square Layer Normalization.\n",
        "\n",
        "    Paper: \"Root Mean Square Layer Normalization\" (Zhang & Sennrich, 2019)\n",
        "    https://arxiv.org/abs/1910.07467\n",
        "\n",
        "    Key implementation details from paper:\n",
        "    - RMS(x) = sqrt(mean(x^2) + eps)\n",
        "    - Output = gamma * (x / RMS(x))\n",
        "    - No mean centering (unlike LayerNorm)\n",
        "    - No bias parameter\n",
        "\n",
        "    Args:\n",
        "        d: Model dimension\n",
        "        eps: Small constant for numerical stability (default: 1e-6)\n",
        "    \"\"\"\n",
        "    def __init__(self, d: int, eps: float = 1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "        # TODO: Create learnable scale parameter initialized to ones\n",
        "        # Hint: Use nn.Parameter with torch.ones\n",
        "        # Shape should be (d,)\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.scale = nn.Parameter(torch.ones(d))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape (B, S, d)\n",
        "\n",
        "        Returns:\n",
        "            Normalized tensor of shape (B, S, d)\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        # first step is to do RMS\n",
        "        rms = torch.rsqrt(x.pow(2).mean(dim=-1, keepdim=True) + self.eps)\n",
        "        x_norm = x * rms * self.scale\n",
        "        return x_norm\n",
        "        # Alternative implementation:\n",
        "        # rms = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + self.eps)\n",
        "        # x_norm = x / rms\n",
        "        # return self.scale * x_norm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_77bPGi4UVCH"
      },
      "source": [
        "### 1.2 SwiGLU Feed-Forward Network [3 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaME5ZMeUYBz"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    SwiGLU Feed-Forward Network.\n",
        "\n",
        "    Paper: \"GLU Variants Improve Transformer\" (Shazeer, 2020)\n",
        "    https://arxiv.org/abs/2002.05202\n",
        "\n",
        "    Key implementation details from paper:\n",
        "    - FFN_SwiGLU(x) = (Swish(xW1) ⊙ xV) W2\n",
        "    - Swish(x) = x * sigmoid(x), also known as SiLU\n",
        "    - Two parallel projections (gate and value)\n",
        "    - Standard output projection\n",
        "    - All projections are bias-free\n",
        "\n",
        "    Args:\n",
        "        d: Model dimension\n",
        "        d_ff: Hidden dimension (typically 4*d, or 8d/3 for SwiGLU to match params)\n",
        "        dropout_prob: Dropout probability\n",
        "    \"\"\"\n",
        "    def __init__(self, d: int, d_ff: int, dropout_prob: float):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: Define three linear layers (all bias=False)\n",
        "        # - w_gate: d -> d_ff (gate path, will apply Swish)\n",
        "        # - w_value: d -> d_ff (value path, stays linear)\n",
        "        # - w_out: d_ff -> d (output projection)\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.w_gate = nn.Linear(d, d_ff, bias=False)\n",
        "        self.w_value = nn.Linear(d, d_ff, bias=False)\n",
        "        self.w_out = nn.Linear(d_ff, d, bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape (B, S, d)\n",
        "\n",
        "        Returns:\n",
        "            Output tensor of shape (B, S, d)\n",
        "        \"\"\"\n",
        "        # pass  # YOUR CODE HERE\n",
        "        swiglu = self.w_out(torch.nn.functional.silu(self.w_gate(x)) * self.w_value(x))\n",
        "        # we apply dropout after the output projection because it's common to apply dropout on the output of FFN layers. \n",
        "        # The real reason is to prevent overfitting and improve generalization.\n",
        "        return self.dropout(swiglu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7nfeRx3UdPQ"
      },
      "source": [
        "### 1.3 RoPE: Rotary Position Embeddings [6 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzrfOWC1UZ-m"
      },
      "outputs": [],
      "source": [
        "from networkx import omega\n",
        "\n",
        "\n",
        "def rotate_half(t: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Helper function for RoPE: rotates pairs of elements.\n",
        "\n",
        "    Paper: \"RoFormer: Enhanced Transformer with Rotary Position Embedding\" (Su et al., 2021)\n",
        "    https://arxiv.org/abs/2104.09864\n",
        "\n",
        "    Transforms [x0, x1, x2, x3, ...] -> [-x1, x0, -x3, x2, ...]\n",
        "    This implements the rotation matrix in complex number form.\n",
        "\n",
        "    Args:\n",
        "        t: Tensor of shape (..., d) where d is even\n",
        "\n",
        "    Returns:\n",
        "        Rotated tensor of shape (..., d)\n",
        "    \"\"\"\n",
        "    # pass  # YOUR CODE HERE\n",
        "    dimension = t.shape[-1]\n",
        "    assert dimension % 2 == 0, \"dimensionimension must be even for rotate_half\"\n",
        "    t1 = []\n",
        "    for i in range(dimension):\n",
        "        if i % 2 == 0:\n",
        "            t1.append(t[..., i])\n",
        "        else:\n",
        "            t1.insert(i-1, -1*t[..., i])\n",
        "    t1 = torch.stack(t1, dim=-1)\n",
        "\n",
        "    return t1\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "def apply_rope(x: torch.Tensor, positions: torch.Tensor,\n",
        "               d_rope: Optional[int] = None, theta: float = 10000.0) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Apply Rotary Position Embeddings to input tensor.\n",
        "\n",
        "    Paper details:\n",
        "    - Rotation angles: theta_j = position * base^(-2j/d_rope)\n",
        "    - Applied as: x * cos(theta) + rotate_half(x) * sin(theta)\n",
        "    - Only rotates first d_rope dimensions (partial rotation)\n",
        "    - Base frequency typically 10000 (for context length ~2048)\n",
        "\n",
        "    Args:\n",
        "        x: Input tensor of shape (B, S, H, d_h)\n",
        "        positions: Position indices of shape (S,)\n",
        "        d_rope: Dimension to apply rotation (if None, use all d_h)\n",
        "        theta: Base frequency (default: 10000)\n",
        "\n",
        "    Returns:\n",
        "        Rotated tensor of shape (B, S, H, d_h)\n",
        "    \"\"\"\n",
        "    B, S, H, d_h = x.shape\n",
        "\n",
        "    # Use full dimension if d_rope not specified\n",
        "    if d_rope is None:\n",
        "        d_rope = d_h\n",
        "    assert d_rope <= d_h and d_rope % 2 == 0, \"d_rope must be even and <= d_h\"\n",
        "\n",
        "    device = x.device\n",
        "    \n",
        "    # TODO: Implement RoPE\n",
        "    # Step 1: Compute inverse frequencies\n",
        "    # pass  # YOUR CODE HERE\n",
        "    omega = theta\n",
        "    inverse_frequcy = [omega**(-2*j/d_rope) for j in range(d_rope//2)]\n",
        "\n",
        "    # Step 2: Build angle matrix of shape (S, d_rope/2)\n",
        "    # pass  # YOUR CODE HERE\n",
        "    theta = positions.unsqueeze(1) * torch.tensor(inverse_frequcy, device=device).unsqueeze(0)  # (S, d_rope/2)\n",
        "    # Step 3: Repeat angles to match d_rope dimension\n",
        "    # Create cos and sin angles for the rotation matrix\n",
        "    # pass  # YOUR CODE HERE\n",
        "    cos_theta = torch.cos(theta).repeat_interleave(2, dim=-1)  # (S, d_rope)\n",
        "    sin_theta = torch.sin(theta).repeat_interleave(2, dim=-1)  # (S, d_rope)\n",
        "\n",
        "    # Step 4: Apply rotation to first d_rope channels\n",
        "    x_rotated = (x[..., :d_rope] * cos_theta.unsqueeze(1) +\n",
        "                 rotate_half(x[..., :d_rope]) * sin_theta.unsqueeze(1))\n",
        "\n",
        "    # Step 5: Concatenate with unchanged channels if d_rope < d_h\n",
        "    if d_rope < d_h:\n",
        "        x_rotated = torch.cat([x_rotated, x[..., d_rope:]], dim=-1)\n",
        "   # Return rotated tensor with shape (B, S, H, dh)\n",
        "    return x_rotated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeUxOv7kUh5z"
      },
      "source": [
        "### 1.4 Grouped-Query Attention (GQA) [12 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeVTOZ_uUjrF"
      },
      "outputs": [],
      "source": [
        "class GroupedQueryAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Grouped-Query Attention mechanism.\n",
        "\n",
        "    Paper: \"GQA: Training Generalized Multi-Query Transformer Models\" (Ainslie et al., 2023)\n",
        "    https://arxiv.org/abs/2305.13245\n",
        "\n",
        "    Key implementation details:\n",
        "    - Q has H heads, K and V have G groups where G < H and G divides H\n",
        "    - Each KV group is shared across H/G query heads\n",
        "    - Memory efficient: reduces KV cache size by factor of H/G\n",
        "    - Use repeat_interleave to broadcast KV groups to query heads\n",
        "\n",
        "    Args:\n",
        "        d: Model dimension\n",
        "        num_heads: Number of query heads (H)\n",
        "        num_kv_groups: Number of key-value groups (G), must divide num_heads\n",
        "        dropout_prob: Dropout probability\n",
        "        d_rope: Dimension for RoPE (if None, uses d_h)\n",
        "    \"\"\"\n",
        "    def __init__(self, d: int, num_heads: int, num_kv_groups: int,\n",
        "                 dropout_prob: float, d_rope: Optional[int] = None):\n",
        "        super().__init__()\n",
        "        assert d % num_heads == 0, \"d must be divisible by num_heads\"\n",
        "        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n",
        "\n",
        "        self.d = d\n",
        "        self.num_heads = num_heads\n",
        "        self.num_kv_groups = num_kv_groups\n",
        "        self.d_h = d // num_heads\n",
        "        self.d_rope = d_rope if d_rope is not None else self.d_h\n",
        "\n",
        "        # TODO: Define linear projections (all bias=False): query, key-value, output\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.w_query = nn.Linear(d, d, bias=False)  # Projects to H·d_h = d\n",
        "        self.w_kv = nn.Linear(d, 2 * self.d_h * num_kv_groups, bias=False)  # Projects to 2·G·d_h\n",
        "        self.w_output = nn.Linear(d, d, bias=False)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape (B, S, d)\n",
        "\n",
        "        Returns:\n",
        "            output: Context tensor of shape (B, S, d)\n",
        "            attn_weights: Attention weights of shape (B, H, S, S)\n",
        "        \"\"\"\n",
        "        B, S, d = x.shape\n",
        "\n",
        "        # TODO: Step 1 - Project to Q, K, V\n",
        "        # pass  # YOUR CODE HERE\n",
        "        Q = self.w_query(x)  # (B, S, d)\n",
        "        KV = self.w_kv(x)    # (B, S, 2·G·d_h)\n",
        "\n",
        "\n",
        "        # TODO: Step 2 - Reshape Q to separate heads\n",
        "        # pass  # YOUR CODE HERE\n",
        "        q = Q.view(B, S, self.num_heads, self.d_h)  # (B, S, H, d_h) # view reshape the same data but with different shape\n",
        "\n",
        "        # TODO: Step 3 - Reshape and split KV to get K and V\n",
        "        # pass  # YOUR CODE HERE\n",
        "        kv = KV.view(B, S, self.num_kv_groups, 2 * self.d_h)  # (B, S, G, 2·d_h) #TODO check if it's just d_h or 2*d_h\n",
        "        k, v = kv.split(self.d_h, dim=-1)  # each (B, S, G, d_h)\n",
        "\n",
        "        # TODO: Step 4 - Broadcast K and V to match query heads\n",
        "        # pass  # YOUR CODE HERE\n",
        "        k = k.repeat_interleave(self.num_heads // self.num_kv_groups, dim=2)  # (B, S, H, d_h)\n",
        "        v = v.repeat_interleave(self.num_heads // self.num_kv_groups, dim=2)  # (B, S, H, d_h)\n",
        "\n",
        "        # TODO: Step 5 - Apply RoPE to Q and K\n",
        "        # pass  # YOUR CODE HERE\n",
        "        positions = torch.arange(S)\n",
        "        q = apply_rope(q, positions, self.d_rope)\n",
        "        k = apply_rope(k, positions, self.d_rope)\n",
        "\n",
        "        # TODO: Step 6 - Transpose for attention computation\n",
        "        # pass  # YOUR CODE HERE\n",
        "        q = q.transpose(1, 2)  # (B, num_heads, S, d_h)\n",
        "        k = k.transpose(1, 2)  # (B, num_heads, S, d_h)\n",
        "        v = v.transpose(1, 2)  # (B, num_heads, S, d_h)\n",
        "\n",
        "        # TODO: Step 7 - Compute scaled dot-product attention scores\n",
        "        # pass  # YOUR CODE HERE\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_h)  # (B, H, S, S)\n",
        "        \n",
        "\n",
        "        # TODO: Step 8 - Apply causal mask\n",
        "        # pass  # YOUR CODE HERE\n",
        "        mask = torch.triu(torch.ones(S, S), diagonal=1)\n",
        "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
        "        mask.unsqueeze(0).unsqueeze(0)  # (1, 1, S, S)\n",
        "        scores = scores + mask  # Apply the mask to the scores\n",
        "\n",
        "        # TODO: Step 9 - Apply softmax and dropout\n",
        "        # pass  # YOUR CODE HERE\n",
        "        attn_weights = torch.softmax(scores, dim=-1)  # (B, H, S, S)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # TODO: Step 10 - Apply attention to values\n",
        "        # pass  # YOUR CODE HERE\n",
        "        context = torch.matmul(attn_weights, v)  # (B, H, S, d_h)\n",
        "        context = context.transpose(1, 2).contiguous().view(B, S, d)  # (B, S, d)\n",
        "\n",
        "        # TODO: Step 11 - Concatenate heads and project\n",
        "        # pass  # YOUR CODE HERE\n",
        "        output = self.w_output(context)  # (B, S, d)\n",
        "        output = self.dropout(output) # Note: dropout after output projection not sure if it's necessary\n",
        "        return output, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JicJ29ryUlDS"
      },
      "source": [
        "### 1.5 Decoder Block with Parallel Pre-Normalization [3 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gYj9nvIUqyr"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer decoder block with parallel pre-normalization.\n",
        "\n",
        "    Architecture based on modern LLMs (e.g., PaLM, LLaMA):\n",
        "    - Pre-normalization (norm before attention/FFN, not after)\n",
        "    - Parallel formulation: both branches normalize the same input\n",
        "    - Equation: y = x + Dropout(Attn(Norm(x))) + Dropout(FFN(Norm(x)))\n",
        "\n",
        "    Note: This differs from sequential (GPT-2 style) where FFN sees attention output\n",
        "\n",
        "    Args:\n",
        "        d: Model dimension\n",
        "        num_heads: Number of attention heads\n",
        "        num_kv_groups: Number of key-value groups\n",
        "        d_ff: Feed-forward hidden dimension\n",
        "        dropout_prob: Dropout probability\n",
        "    \"\"\"\n",
        "    def __init__(self, d: int, num_heads: int, num_kv_groups: int,\n",
        "                 d_ff: int, dropout_prob: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: Create two RMSNorm instances (one for attention path, one for FFN path)\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.attn_RMSNorm = RMSNorm(d=d)\n",
        "        self.FFN_RMSNorm = RMSNorm(d=d)\n",
        "\n",
        "        # TODO: Create GroupedQueryAttention and FeedForward instances\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.group_attention = GroupedQueryAttention(d=d, num_heads=num_heads, num_kv_groups=num_kv_groups,dropout_prob=0.1)\n",
        "        self.feed_forward = FeedForward(d=d, d_ff=d_ff, dropout_prob=dropout_prob)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass with parallel pre-normalization.\n",
        "\n",
        "        Args:\n",
        "            x: Input tensor of shape (B, S, d)\n",
        "\n",
        "        Returns:\n",
        "            output: Output tensor of shape (B, S, d)\n",
        "            attn_weights: Attention weights of shape (B, H, S, S)\n",
        "        \"\"\"\n",
        "        # TODO: Implement parallel pre-normalization\n",
        "        # Step 1: Attention branch\n",
        "        # Step 2: FFN branch (normalizes the SAME input x, not attn output)\n",
        "        # Step 3: Sum both branches with input residual\n",
        "\n",
        "        # pass  # YOUR CODE HERE\n",
        "        attn_input = self.attn_RMSNorm(x)\n",
        "        attn_output, attn_weights = self.group_attention(attn_input)\n",
        "\n",
        "        ffn_input = self.FFN_RMSNorm(x)\n",
        "        ffn_output = self.feed_forward(ffn_input)\n",
        "\n",
        "        output = x + self.dropout(attn_output) + self.dropout(ffn_output)\n",
        "        return output, attn_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSq1qSzQFPy0"
      },
      "source": [
        "### 1.6 Complete Model: ModernDecoderLM [3 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1nM7oF6FNJd"
      },
      "outputs": [],
      "source": [
        "class ModernDecoderLM(nn.Module):\n",
        "    \"\"\"\n",
        "    Modern decoder-only language model with state-of-the-art components.\n",
        "\n",
        "    Architecture features:\n",
        "    - Token embeddings only (no absolute positional embeddings - RoPE handles this)\n",
        "    - Stack of decoder blocks with parallel pre-norm\n",
        "    - Final RMSNorm before output\n",
        "    - Weight tying: embedding weights shared with LM head\n",
        "\n",
        "    Args:\n",
        "        vocab_size: Vocabulary size\n",
        "        d: Model dimension\n",
        "        num_layers: Number of decoder layers\n",
        "        num_heads: Number of attention heads\n",
        "        num_kv_groups: Number of key-value groups\n",
        "        d_ff: Feed-forward hidden dimension\n",
        "        dropout_prob: Dropout probability\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size: int, d: int, num_layers: int,\n",
        "                 num_heads: int, num_kv_groups: int, d_ff: int,\n",
        "                 dropout_prob: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.d = d\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # TODO: Create token embedding (no positional embeddings - RoPE handles positions)\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d)\n",
        "        # TODO: Create stack of decoder blocks using nn.ModuleList. L instances of DecoderBlock stacked sequentially.\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.decoder_blocks = nn.ModuleList([\n",
        "            DecoderBlock(d=d, num_heads=num_heads, num_kv_groups=num_kv_groups,\n",
        "                         d_ff=d_ff, dropout_prob=dropout_prob)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        # TODO: Create final normalization layer\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.final_norm = RMSNorm(d=d)\n",
        "\n",
        "        # TODO: Create language model head (linear projection to vocabulary)\n",
        "        # Then implement weight tying\n",
        "        # pass  # YOUR CODE HERE\n",
        "        self.lm_head = nn.Linear(d, vocab_size, bias=False)\n",
        "        self.lm_head.weight = self.token_embedding.weight \n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Token indices of shape (B, S)\n",
        "\n",
        "        Returns:\n",
        "            logits: Logits of shape (B, S, vocab_size)\n",
        "            hidden_states: Hidden states of shape (L, B, S, d)\n",
        "            attn_weights: Attention weights of shape (L, B, H, S, S)\n",
        "        \"\"\"\n",
        "        # TODO: Implement forward pass\n",
        "        # Step 1: Embed tokens\n",
        "        # Step 2: Pass through decoder stack, collecting hidden states and attention weights\n",
        "        # Step 3: Apply final normalization\n",
        "        # Step 4: Project to vocabulary\n",
        "        # Step 5: Stack hidden states and attention weights into tensors\n",
        "\n",
        "        # pass  # YOUR CODE HERE\n",
        "        x = self.token_embedding(input_ids)\n",
        "\n",
        "        hidden_states = []\n",
        "        attn_weights_list = []\n",
        "        for block in self.decoder_blocks:\n",
        "            x, attn = block(x)\n",
        "            hidden_states.append(x)\n",
        "            attn_weights_list.append(attn)\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        hidden_states = torch.stack(hidden_states)\n",
        "        attn_weights = torch.stack(attn_weights_list)\n",
        "\n",
        "        return logits, hidden_states, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXTVzbcSUugW"
      },
      "source": [
        "## Section 2: Dataset Generation (DO NOT MODIFY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGqDsjU7Uu6b"
      },
      "outputs": [],
      "source": [
        "def create_modular_arithmetic_dataset(p=11, train_split=0.9, seed=42):\n",
        "    \"\"\"\n",
        "    Generate modular arithmetic dataset.\n",
        "\n",
        "    Creates equations over Z/pZ (integers modulo p):\n",
        "    - Binary: [BOS] a op b [=] r [EOS] [PAD] [PAD]\n",
        "    - Ternary: [BOS] a op b op c [=] r [EOS]\n",
        "    where op ∈ {+, *} and r is result mod p\n",
        "\n",
        "    Args:\n",
        "        p: Modulus (prime number, default 11)\n",
        "        train_split: Fraction of data for training (default 0.9)\n",
        "        seed: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        train_inputs: Training input sequences (N_train, S-1)\n",
        "        train_targets: Training target sequences (N_train, S-1)\n",
        "        val_inputs: Validation input sequences (N_val, S-1)\n",
        "        val_targets: Validation target sequences (N_val, S-1)\n",
        "        vocab: Vocabulary dictionary\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Vocabulary: digits 0-(p-1), +, *, [BOS], [EOS], [PAD], [=]\n",
        "    vocab = {\n",
        "        'token_to_idx': {},\n",
        "        'idx_to_token': {}\n",
        "    }\n",
        "\n",
        "    # Assign indices\n",
        "    for i in range(p):\n",
        "        vocab['token_to_idx'][str(i)] = i\n",
        "        vocab['idx_to_token'][i] = str(i)\n",
        "\n",
        "    vocab['token_to_idx']['+'] = p\n",
        "    vocab['token_to_idx']['*'] = p + 1\n",
        "    vocab['token_to_idx']['[BOS]'] = p + 2\n",
        "    vocab['token_to_idx']['[EOS]'] = p + 3\n",
        "    vocab['token_to_idx']['[PAD]'] = p + 4\n",
        "    vocab['token_to_idx']['[=]'] = p + 5\n",
        "\n",
        "    for i in range(p, p + 6):\n",
        "        vocab['idx_to_token'][i] = list(vocab['token_to_idx'].keys())[list(vocab['token_to_idx'].values()).index(i)]\n",
        "\n",
        "    BOS, EOS, PAD, EQ = p + 2, p + 3, p + 4, p + 5\n",
        "    ADD, MUL = p, p + 1\n",
        "    sequences = []\n",
        "\n",
        "    # Binary operations: [BOS] a op b [=] r [EOS] [PAD] [PAD]\n",
        "    for op in [ADD, MUL]:\n",
        "        for a in range(p):\n",
        "            for b in range(p):\n",
        "                r = (a + b) % p if op == ADD else (a * b) % p\n",
        "                seq = [BOS, a, op, b, EQ, r, EOS, PAD]\n",
        "                sequences.append(seq)\n",
        "\n",
        "    # Ternary operations: [BOS] a op b op c [=] r [EOS]\n",
        "    for op in [ADD, MUL]:\n",
        "        for a in range(p):\n",
        "            for b in range(p):\n",
        "                for c in range(p):\n",
        "                    r = (a + b + c) % p if op == ADD else (a * b * c) % p\n",
        "                    seq = [BOS, a, op, b, op, c, EQ, r]\n",
        "                    sequences.append(seq)\n",
        "\n",
        "    sequences = np.array(sequences)\n",
        "\n",
        "    # Shuffle and split\n",
        "    indices = np.random.permutation(len(sequences))\n",
        "    split_idx = int(len(sequences) * train_split)\n",
        "\n",
        "    train_seqs = sequences[indices[:split_idx]]\n",
        "    val_seqs = sequences[indices[split_idx:]]\n",
        "\n",
        "    # Convert to tensors (input is all but last, target is all but first)\n",
        "    train_inputs = torch.LongTensor(train_seqs[:, :-1])\n",
        "    train_targets = torch.LongTensor(train_seqs[:, 1:])\n",
        "    val_inputs = torch.LongTensor(val_seqs[:, :-1])\n",
        "    val_targets = torch.LongTensor(val_seqs[:, 1:])\n",
        "\n",
        "    return train_inputs, train_targets, val_inputs, val_targets, vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mGVTWsJRpuu"
      },
      "source": [
        "## Section 3: Training and Evaluation Infrastructure (DO NOT MODIFY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adETdDEQR0va"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(logits, targets, vocab):\n",
        "    \"\"\"\n",
        "    Compute loss and accuracy on tokens after [=] sign only.\n",
        "\n",
        "    Args:\n",
        "        logits: Model logits (B, S, V)\n",
        "        targets: Target tokens (B, S)\n",
        "        vocab: Vocabulary dictionary\n",
        "\n",
        "    Returns:\n",
        "        loss: Mean cross-entropy loss on RHS tokens\n",
        "        accuracy: Sequence-level accuracy (all RHS tokens correct)\n",
        "    \"\"\"\n",
        "    B, S, V = logits.shape\n",
        "    EQ_idx = vocab['token_to_idx']['[=]']\n",
        "    PAD_idx = vocab['token_to_idx']['[PAD]']\n",
        "    EOS_idx = vocab['token_to_idx']['[EOS]']\n",
        "\n",
        "    # Create mask for tokens after [=] (excluding [PAD] and [EOS])\n",
        "    eq_mask = (targets == EQ_idx)\n",
        "    mask = torch.zeros_like(targets, dtype=torch.bool)\n",
        "\n",
        "    for i in range(B):\n",
        "        eq_positions = torch.where(eq_mask[i])[0]\n",
        "        if len(eq_positions) > 0:\n",
        "            eq_pos = eq_positions[0].item()\n",
        "            for j in range(eq_pos + 1, S):\n",
        "                if targets[i, j] != PAD_idx and targets[i, j] != EOS_idx:\n",
        "                    mask[i, j] = True\n",
        "\n",
        "    if mask.sum() == 0:\n",
        "        return torch.tensor(0.0, device=logits.device), torch.tensor(0.0, device=logits.device)\n",
        "\n",
        "    # Compute loss on masked tokens\n",
        "    logits_flat = logits.view(-1, V)[mask.view(-1)]\n",
        "    targets_flat = targets.view(-1)[mask.view(-1)]\n",
        "    loss = F.cross_entropy(logits_flat, targets_flat)\n",
        "\n",
        "    # Compute sequence-level accuracy\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    correct_tokens = (preds == targets) | (~mask)\n",
        "    correct_sequences = correct_tokens.all(dim=1).float().mean()\n",
        "\n",
        "    return loss, correct_sequences\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    \"\"\"\n",
        "    Cosine learning rate schedule with linear warmup.\n",
        "\n",
        "    LR increases linearly from 0 to max_lr during warmup,\n",
        "    then decreases following cosine curve to 0.\n",
        "    \"\"\"\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, vocab, config, device):\n",
        "    \"\"\"\n",
        "    Train the model with AdamW optimizer and cosine schedule.\n",
        "\n",
        "    Args:\n",
        "        model: Model to train\n",
        "        train_loader: Training dataloader\n",
        "        val_loader: Validation dataloader\n",
        "        vocab: Vocabulary dictionary\n",
        "        config: Configuration dictionary with hyperparameters\n",
        "        device: Device to train on\n",
        "\n",
        "    Returns:\n",
        "        history: Dictionary with training history\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                                   lr=config['learning_rate'],\n",
        "                                   weight_decay=config['weight_decay'])\n",
        "\n",
        "    num_training_steps = config['num_epochs'] * len(train_loader)\n",
        "    num_warmup_steps = int(0.1 * num_training_steps)\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': [],\n",
        "        'steps': []\n",
        "    }\n",
        "\n",
        "    if 'track_param_norm' in config and config['track_param_norm']:\n",
        "        history['param_norms'] = []\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    step = 0\n",
        "\n",
        "    for epoch in range(config['num_epochs']):\n",
        "        model.train()\n",
        "        train_loss_epoch = []\n",
        "        train_acc_epoch = []\n",
        "\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
        "        for batch_inputs, batch_targets in pbar:\n",
        "            batch_inputs = batch_inputs.to(device)\n",
        "            batch_targets = batch_targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits, _, _ = model(batch_inputs)\n",
        "            loss, acc = compute_metrics(logits, batch_targets, vocab)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['grad_clip'])\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss_epoch.append(loss.item())\n",
        "            train_acc_epoch.append(acc.item())\n",
        "\n",
        "            pbar.set_postfix({'loss': loss.item(), 'acc': acc.item()})\n",
        "            step += 1\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss_list = []\n",
        "        val_acc_list = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_inputs, batch_targets in val_loader:\n",
        "                batch_inputs = batch_inputs.to(device)\n",
        "                batch_targets = batch_targets.to(device)\n",
        "\n",
        "                logits, _, _ = model(batch_inputs)\n",
        "                loss, acc = compute_metrics(logits, batch_targets, vocab)\n",
        "\n",
        "                val_loss_list.append(loss.item())\n",
        "                val_acc_list.append(acc.item())\n",
        "\n",
        "        train_loss_avg = np.mean(train_loss_epoch)\n",
        "        train_acc_avg = np.mean(train_acc_epoch)\n",
        "        val_loss_avg = np.mean(val_loss_list)\n",
        "        val_acc_avg = np.mean(val_acc_list)\n",
        "\n",
        "        history['train_loss'].append(train_loss_avg)\n",
        "        history['train_acc'].append(train_acc_avg)\n",
        "        history['val_loss'].append(val_loss_avg)\n",
        "        history['val_acc'].append(val_acc_avg)\n",
        "        history['steps'].append(step)\n",
        "\n",
        "        # Track parameter norm if requested\n",
        "        if 'track_param_norm' in config and config['track_param_norm']:\n",
        "            param_norm = sum(p.data.norm(2).item() ** 2 for p in model.parameters() if p.requires_grad) ** 0.5\n",
        "            history['param_norms'].append(param_norm)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={train_loss_avg:.4f}, Train Acc={train_acc_avg:.4f}, \"\n",
        "              f\"Val Loss={val_loss_avg:.4f}, Val Acc={val_acc_avg:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc_avg > best_val_acc:\n",
        "            best_val_acc = val_acc_avg\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVHN2rRqSEOh"
      },
      "source": [
        "## Section 4A: Plots and Summary Utilities (DO NOT MODIFY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RorfYPUfU2sI"
      },
      "outputs": [],
      "source": [
        "def plot_training_curves(history, title=\"Training Curves\", save_name=None):\n",
        "    \"\"\"Plot loss and accuracy curves.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    steps = history['steps']\n",
        "\n",
        "    # Loss curves\n",
        "    ax1.plot(steps, history['train_loss'], label='Train Loss', alpha=0.8, linewidth=2, color='#2E86AB')\n",
        "    ax1.plot(steps, history['val_loss'], label='Val Loss', alpha=0.8, linewidth=2, color='#A23B72')\n",
        "    ax1.set_xlabel('Training Steps', fontsize=12)\n",
        "    ax1.set_ylabel('Loss', fontsize=12)\n",
        "    ax1.set_title('Loss Curves', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=11)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy curves\n",
        "    ax2.plot(steps, history['train_acc'], label='Train Accuracy', alpha=0.8, linewidth=2, color='#2E86AB')\n",
        "    ax2.plot(steps, history['val_acc'], label='Val Accuracy', alpha=0.8, linewidth=2, color='#A23B72')\n",
        "    ax2.set_xlabel('Training Steps', fontsize=12)\n",
        "    ax2.set_ylabel('Accuracy', fontsize=12)\n",
        "    ax2.set_title('Accuracy Curves', fontsize=14, fontweight='bold')\n",
        "    ax2.legend(fontsize=11)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.set_ylim([0, 1.05])\n",
        "\n",
        "    plt.suptitle(title, fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_name:\n",
        "        plt.savefig(f\"{save_name}.png\", dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def compute_summary_metrics(history):\n",
        "    \"\"\"Compute summary metrics from training history.\"\"\"\n",
        "    metrics = {\n",
        "        'best_train_loss': min(history['train_loss']),\n",
        "        'best_val_loss': min(history['val_loss']),\n",
        "        'best_train_acc': max(history['train_acc']),\n",
        "        'best_val_acc': max(history['val_acc']),\n",
        "        'step_best_train_loss': history['steps'][np.argmin(history['train_loss'])],\n",
        "        'step_best_val_loss': history['steps'][np.argmin(history['val_loss'])],\n",
        "        'step_best_train_acc': history['steps'][np.argmax(history['train_acc'])],\n",
        "        'step_best_val_acc': history['steps'][np.argmax(history['val_acc'])],\n",
        "    }\n",
        "\n",
        "    metrics['lag_loss'] = metrics['step_best_val_loss'] - metrics['step_best_train_loss']\n",
        "    metrics['lag_acc'] = metrics['step_best_val_acc'] - metrics['step_best_train_acc']\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def print_summary_table(metrics):\n",
        "    \"\"\"Print formatted summary table\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY METRICS\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"{'Metric':<35} {'Value':<20}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Best Train Loss':<35} {metrics['best_train_loss']:.4f}\")\n",
        "    print(f\"{'Best Val Loss':<35} {metrics['best_val_loss']:.4f}\")\n",
        "    print(f\"{'Best Train Accuracy':<35} {metrics['best_train_acc']:.4f}\")\n",
        "    print(f\"{'Best Val Accuracy':<35} {metrics['best_val_acc']:.4f}\")\n",
        "    print(f\"{'Step (Best Train Loss)':<35} {metrics['step_best_train_loss']}\")\n",
        "    print(f\"{'Step (Best Val Loss)':<35} {metrics['step_best_val_loss']}\")\n",
        "    print(f\"{'Step (Best Train Acc)':<35} {metrics['step_best_train_acc']}\")\n",
        "    print(f\"{'Step (Best Val Acc)':<35} {metrics['step_best_val_acc']}\")\n",
        "    print(f\"{'Generalization Lag (Loss)':<35} {metrics['lag_loss']} steps\")\n",
        "    print(f\"{'Generalization Lag (Acc)':<35} {metrics['lag_acc']} steps\")\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulTFdlFmGPyg"
      },
      "source": [
        "## Section 4 B: Visualization Utilities (DO NOT MODIFY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mAcq-A78w3W"
      },
      "outputs": [],
      "source": [
        "def visualize_attention_patterns(model, val_inputs, vocab, device):\n",
        "    \"\"\"Visualize attention patterns for all 5 standardized examples\"\"\"\n",
        "\n",
        "    STANDARD_EXAMPLES = {\n",
        "        'binary_add_small': [13, 2, 11, 3, 16, 5, 14, 15],\n",
        "        'binary_add_carry': [13, 7, 11, 8, 16, 4, 14, 15],\n",
        "        'binary_mult_small': [13, 2, 12, 3, 16, 6, 14, 15],\n",
        "        'ternary_add': [13, 1, 11, 2, 11, 3, 16, 6],\n",
        "        'ternary_mult': [13, 2, 12, 3, 12, 4, 16, 2],\n",
        "    }\n",
        "\n",
        "    EXAMPLE_TITLES = {\n",
        "        'binary_add_small': '1. Binary Addition (Small): [BOS] 2 + 3 [=] 5 [EOS] [PAD]',\n",
        "        'binary_add_carry': '2. Binary Addition (Carry): [BOS] 7 + 8 [=] 4 [EOS] [PAD]',\n",
        "        'binary_mult_small': '3. Binary Multiplication: [BOS] 2 * 3 [=] 6 [EOS] [PAD]',\n",
        "        'ternary_add': '4. Ternary Addition: [BOS] 1 + 2 + 3 [=] 6 [EOS]',\n",
        "        'ternary_mult': '5. Ternary Multiplication: [BOS] 2 * 3 * 4 [=] 2 [EOS]'\n",
        "    }\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for example_key, target_seq in STANDARD_EXAMPLES.items():\n",
        "        # Input is all but last token (for autoregressive prediction)\n",
        "        input_seq = target_seq[:-1]\n",
        "        input_tensor = torch.LongTensor(input_seq)\n",
        "\n",
        "        # Find the example in validation set\n",
        "        found = False\n",
        "        for i in range(len(val_inputs)):\n",
        "            # Compare input sequences (length 7)\n",
        "            if len(val_inputs[i]) == len(input_tensor):\n",
        "                if torch.all(val_inputs[i] == input_tensor):\n",
        "                    example_input = val_inputs[i]\n",
        "                    found = True\n",
        "                    break\n",
        "\n",
        "        if not found:\n",
        "            print(f\"Note: Using constructed example for {example_key}\")\n",
        "            example_input = input_tensor\n",
        "\n",
        "        # Get tokens for labeling (use full sequence for display)\n",
        "        full_seq_tokens = [vocab['idx_to_token'][idx] for idx in target_seq]\n",
        "\n",
        "        # Get attention weights using input sequence\n",
        "        with torch.no_grad():\n",
        "            input_ids = example_input.unsqueeze(0).to(device)\n",
        "            logits, hidden_states, attn_weights = model(input_ids)\n",
        "\n",
        "            # Get last layer attention: (H, S, S) where S is input length\n",
        "            attn = attn_weights[-1, 0].cpu().numpy()\n",
        "\n",
        "        num_heads = attn.shape[0]\n",
        "        seq_len = attn.shape[1]\n",
        "\n",
        "        # Use tokens corresponding to input length\n",
        "        tokens = full_seq_tokens[:seq_len]\n",
        "\n",
        "        # Create visualization\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for h in range(num_heads):\n",
        "            ax = axes[h]\n",
        "            im = ax.imshow(attn[h], cmap='viridis', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "            # Set ticks and labels\n",
        "            ax.set_xticks(range(seq_len))\n",
        "            ax.set_yticks(range(seq_len))\n",
        "            ax.set_xticklabels(tokens, rotation=45, ha='right', fontsize=9)\n",
        "            ax.set_yticklabels(tokens, fontsize=9)\n",
        "\n",
        "            ax.set_title(f'Head {h}', fontsize=12, fontweight='bold')\n",
        "            ax.set_xlabel('Key Position', fontsize=10)\n",
        "            ax.set_ylabel('Query Position', fontsize=10)\n",
        "\n",
        "            # Add colorbar\n",
        "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "        full_title = EXAMPLE_TITLES[example_key]\n",
        "        plt.suptitle(f'Attention Patterns - Final Layer\\n{full_title}',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        filename = f'attention_{example_key}.png'\n",
        "        plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
        "        print(f\"Saved: {filename}\")\n",
        "        plt.show()\n",
        "        print()  # Add spacing between examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7V5IzafMXJF"
      },
      "source": [
        "## Section 5: Experiment 1 - Sanity Check and Baseline [6 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1EaFVfDMb3u"
      },
      "outputs": [],
      "source": [
        "# Generate dataset\n",
        "train_inputs, train_targets, val_inputs, val_targets, vocab = create_modular_arithmetic_dataset(p=11)\n",
        "\n",
        "print(f\"Dataset Statistics:\")\n",
        "print(f\"  Training samples: {len(train_inputs)}\")\n",
        "print(f\"  Validation samples: {len(val_inputs)}\")\n",
        "print(f\"  Vocabulary size: {len(vocab['token_to_idx'])}\")\n",
        "print(f\"  Sequence length: {train_inputs.shape[1]}\")\n",
        "print(f\"  Total equations: {len(train_inputs) + len(val_inputs)}\")\n",
        "\n",
        "# Model configuration\n",
        "config = {\n",
        "    'vocab_size': len(vocab['token_to_idx']),\n",
        "    'd': 128,\n",
        "    'num_layers': 4,\n",
        "    'num_heads': 8,\n",
        "    'num_kv_groups': 4,\n",
        "    'd_ff': 512,\n",
        "    'dropout_prob': 0.1,\n",
        "    'learning_rate': 3e-4,\n",
        "    'weight_decay': 1e-4,\n",
        "    'num_epochs': 100,\n",
        "    'grad_clip': 1.0,\n",
        "    'batch_size': 64,\n",
        "}\n",
        "\n",
        "print(f\"\\nModel Configuration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = config['batch_size']\n",
        "train_dataset = TensorDataset(train_inputs, train_targets)\n",
        "val_dataset = TensorDataset(val_inputs, val_targets)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def init_weights(module):\n",
        "    \"\"\"Initialize model with better weight initialization (small values)\"\"\"\n",
        "    if isinstance(module, nn.Linear):\n",
        "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        if module.bias is not None:\n",
        "            torch.nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "model = ModernDecoderLM(\n",
        "    vocab_size=config['vocab_size'],\n",
        "    d=config['d'],\n",
        "    num_layers=config['num_layers'],\n",
        "    num_heads=config['num_heads'],\n",
        "    num_kv_groups=config['num_kv_groups'],\n",
        "    d_ff=config['d_ff'],\n",
        "    dropout_prob=config['dropout_prob']\n",
        ")\n",
        "model.apply(init_weights)\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal trainable parameters: {num_params:,}\")\n",
        "\n",
        "# Train model\n",
        "print(\"\\nTraining baseline model...\")\n",
        "history_baseline = train_model(model, train_loader, val_loader, vocab, config, device)\n",
        "\n",
        "# SOLUTION: Part A - Generate plots\n",
        "print(\"\\n--- Part A: Training Curves ---\")\n",
        "plot_training_curves(history_baseline, \"Experiment 1: Baseline Training\", \"exp1_baseline_curves\")\n",
        "\n",
        "# SOLUTION: Part B - Summary metrics and table\n",
        "print(\"\\n--- Part B: Summary Metrics ---\")\n",
        "metrics_baseline = compute_summary_metrics(history_baseline)\n",
        "print_summary_table(metrics_baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs_5tbzTkaEv"
      },
      "outputs": [],
      "source": [
        "# print(\"\\n\" + \"=\"*80)\n",
        "# print(\"TODO: Write your interpretation in the PDF report [3 points]:\")\n",
        "# print(\"Address the following questions:\")\n",
        "# print(\"1. Does the model successfully learn the modular arithmetic task?\")\n",
        "# print(\"2. Is there evidence of overfitting or underfitting?\")\n",
        "# print(\"3. How quickly does validation performance follow training performance?\")\n",
        "# print(\"4. What do the generalization lags suggest about task difficulty?\")\n",
        "# print(\"5. Are there any unexpected behaviors in the learning curves?\")\n",
        "# print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjwJ0hiULHeV"
      },
      "source": [
        "## Section 6: Experiment 2 - Regularization and Optimization [8 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilkCJRl8j9y9"
      },
      "source": [
        "### Part A: Dropout Sweep [4 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQZin82IkH_F"
      },
      "outputs": [],
      "source": [
        "dropout_values = [0.0, 0.2, 0.4]\n",
        "dropout_histories = {}\n",
        "\n",
        "for dropout_prob in dropout_values:\n",
        "    print(f\"\\nTraining with dropout={dropout_prob}\")\n",
        "\n",
        "    config_dropout = config.copy()\n",
        "    config_dropout['dropout_prob'] = dropout_prob\n",
        "    config_dropout['num_epochs'] = 100\n",
        "\n",
        "    model_dropout = ModernDecoderLM(\n",
        "        vocab_size=config_dropout['vocab_size'],\n",
        "        d=config_dropout['d'],\n",
        "        num_layers=config_dropout['num_layers'],\n",
        "        num_heads=config_dropout['num_heads'],\n",
        "        num_kv_groups=config_dropout['num_kv_groups'],\n",
        "        d_ff=config_dropout['d_ff'],\n",
        "        dropout_prob=config_dropout['dropout_prob']\n",
        "    )\n",
        "    model_dropout.apply(init_weights)\n",
        "\n",
        "    history_dropout = train_model(model_dropout, train_loader, val_loader,\n",
        "                                   vocab, config_dropout, device)\n",
        "    dropout_histories[dropout_prob] = history_dropout\n",
        "\n",
        "# Plot comparison of dropout values\n",
        "print(\"\\nPlotting dropout comparison...\")\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "colors = {'0.0': '#E63946', '0.2': '#2A9D8F', '0.4': '#F77F00'}\n",
        "\n",
        "for dropout_prob, history in dropout_histories.items():\n",
        "    color = colors[str(dropout_prob)]\n",
        "    label = f'Dropout={dropout_prob}'\n",
        "\n",
        "    axes[0, 0].plot(history['steps'], history['train_loss'],\n",
        "                    label=label, alpha=0.8, linewidth=2, color=color)\n",
        "    axes[0, 1].plot(history['steps'], history['val_loss'],\n",
        "                    label=label, alpha=0.8, linewidth=2, color=color)\n",
        "    axes[1, 0].plot(history['steps'], history['train_acc'],\n",
        "                    label=label, alpha=0.8, linewidth=2, color=color)\n",
        "    axes[1, 1].plot(history['steps'], history['val_acc'],\n",
        "                    label=label, alpha=0.8, linewidth=2, color=color)\n",
        "\n",
        "titles = ['Training Loss', 'Validation Loss', 'Training Accuracy', 'Validation Accuracy']\n",
        "for ax, title in zip(axes.flat, titles):\n",
        "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('Steps', fontsize=10)\n",
        "    ax.set_ylabel(title.split()[-1], fontsize=10)\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    if 'Accuracy' in title:\n",
        "        ax.set_ylim([0, 1.05])\n",
        "\n",
        "plt.suptitle('Experiment 2A: Dropout Comparison', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('exp2a_dropout_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# SOLUTION: Summary table\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DROPOUT SWEEP SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Dropout':<12} {'Best Val Loss':<16} {'Best Val Acc':<16} {'Lag (Acc)':<15}\")\n",
        "print(\"-\" * 60)\n",
        "for dropout_prob, history in dropout_histories.items():\n",
        "    metrics_drop = compute_summary_metrics(history)\n",
        "    print(f\"{dropout_prob:<12} {metrics_drop['best_val_loss']:<16.4f} \"\n",
        "          f\"{metrics_drop['best_val_acc']:<16.4f} {metrics_drop['lag_acc']:<15}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iE0cOxlGkS1b"
      },
      "outputs": [],
      "source": [
        "# print(\"\\n\" + \"=\"*80)\n",
        "# print(\"TODO: Write your analysis in the PDF report [2 points]:\")\n",
        "# print(\"Address the following questions:\")\n",
        "# print(\"1. Which dropout value yields the best validation performance? Why?\")\n",
        "# print(\"2. Explain the trade-off between underfitting (too much dropout)\")\n",
        "# print(\"   and overfitting (too little dropout).\")\n",
        "# print(\"3. How does dropout affect the generalization lag?\")\n",
        "# print(\"4. Is there a clear optimal dropout rate for this task?\")\n",
        "# print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LcPt9ojnZ-a"
      },
      "source": [
        "### Part B: Weight Decay Analysis [4 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV3c5hkknn2v"
      },
      "outputs": [],
      "source": [
        "weight_decay_values = [2.5e-4, 5e-4, 1e-3]\n",
        "weight_decay_histories = {}\n",
        "\n",
        "for wd in weight_decay_values:\n",
        "    print(f\"\\nTraining with weight_decay={wd}\")\n",
        "\n",
        "    config_wd = config.copy()\n",
        "    config_wd['weight_decay'] = wd\n",
        "    config_wd['num_epochs'] = 100\n",
        "    config_wd['track_param_norm'] = True\n",
        "\n",
        "    model_wd = ModernDecoderLM(\n",
        "        vocab_size=config_wd['vocab_size'],\n",
        "        d=config_wd['d'],\n",
        "        num_layers=config_wd['num_layers'],\n",
        "        num_heads=config_wd['num_heads'],\n",
        "        num_kv_groups=config_wd['num_kv_groups'],\n",
        "        d_ff=config_wd['d_ff'],\n",
        "        dropout_prob=config_wd['dropout_prob']\n",
        "    )\n",
        "    model_wd.apply(init_weights)\n",
        "\n",
        "    history_wd = train_model(model_wd, train_loader, val_loader, vocab, config_wd, device)\n",
        "    weight_decay_histories[wd] = history_wd\n",
        "\n",
        "# Plot parameter norms\n",
        "print(\"\\nPlotting parameter norms...\")\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "colors_wd = {2.5e-4: '#264653', 5e-4: '#2A9D8F', 1e-3: '#E76F51'}\n",
        "\n",
        "# Parameter norms\n",
        "for wd, history in weight_decay_histories.items():\n",
        "    if 'param_norms' in history:\n",
        "        color = colors_wd[wd]\n",
        "        ax1.plot(history['steps'], history['param_norms'],\n",
        "                 label=f'WD={wd}', alpha=0.8, linewidth=2, color=color)\n",
        "\n",
        "ax1.set_xlabel('Training Steps', fontsize=12)\n",
        "ax1.set_ylabel('L2 Parameter Norm', fontsize=12)\n",
        "ax1.set_title('Parameter Norm vs Training Steps', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Validation accuracy\n",
        "for wd, history in weight_decay_histories.items():\n",
        "    color = colors_wd[wd]\n",
        "    ax2.plot(history['steps'], history['val_acc'],\n",
        "             label=f'WD={wd}', alpha=0.8, linewidth=2, color=color)\n",
        "\n",
        "ax2.set_xlabel('Training Steps', fontsize=12)\n",
        "ax2.set_ylabel('Validation Accuracy', fontsize=12)\n",
        "ax2.set_title('Validation Accuracy vs Training Steps', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim([0, 1.05])\n",
        "\n",
        "plt.suptitle('Experiment 2B: Weight Decay Analysis', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('exp2b_weight_decay_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# SOLUTION: Summary table\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"WEIGHT DECAY SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Weight Decay':<18} {'Best Val Acc':<18} {'Final Param Norm':<20}\")\n",
        "print(\"-\" * 60)\n",
        "for wd, history in weight_decay_histories.items():\n",
        "    best_val_acc = max(history['val_acc'])\n",
        "    final_norm = history['param_norms'][-1] if 'param_norms' in history else 0.0\n",
        "    print(f\"{wd:<18} {best_val_acc:<18.4f} {final_norm:<20.2f}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yKxkogMlHCq",
        "outputId": "97f933e2-939d-4c94-9538-e3f5df945787"
      },
      "outputs": [],
      "source": [
        "# print(\"\\n\" + \"=\"*80)\n",
        "# print(\"TODO: Write your discussion in the PDF report [2 points]:\")\n",
        "# print(\"Address the following questions:\")\n",
        "# print(\"1. How does weight decay affect parameter norms over training?\")\n",
        "# print(\"2. Is there a correlation between norm magnitude and validation performance?\")\n",
        "# print(\"3. What does this suggest about weight decay's role in preventing overfitting?\")\n",
        "# print(\"4. Which weight decay value provides the best balance?\")\n",
        "# print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRCdv3WSmsa1"
      },
      "source": [
        "### Section 7: Experiment 3 - Attention Pattern Visualization [6 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ywhrs-gTU_Aw"
      },
      "outputs": [],
      "source": [
        "# Load best baseline model\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(\"Loaded best baseline model checkpoint\")\n",
        "\n",
        "print(\"\\nGenerating attention visualizations for all 5 standardized examples...\")\n",
        "visualize_attention_patterns(model, val_inputs, vocab, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFiZ01ArpgDK",
        "outputId": "6bb7d545-1c96-4c47-aa05-5d9ad0778d36"
      },
      "outputs": [],
      "source": [
        "# print(\"\\n\" + \"=\"*80)\n",
        "# print(\"TODO: Write your interpretability analysis in the PDF report [3 points]:\")\n",
        "# print(\"For each of the 5 examples, analyze the attention patterns:\")\n",
        "# print(\"1. Do tokens after [=] attend back to the operands and operators?\")\n",
        "# print(\"2. Do different heads exhibit different specializations?\")\n",
        "# print(\"   (e.g., local vs. global attention, operator-focused vs. operand-focused)\")\n",
        "# print(\"3. Can you identify any heads that seem to implement specific\")\n",
        "# print(\"   algorithmic components (e.g., carrying information forward)?\")\n",
        "# print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReQxnt0Cny3v"
      },
      "source": [
        "## Section 8: Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uupdLI22n9J_"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    'experiment_1': {\n",
        "        'history': history_baseline,\n",
        "        'metrics': metrics_baseline,\n",
        "        'config': config\n",
        "    },\n",
        "    'experiment_2a': {\n",
        "        'dropout_histories': dropout_histories,\n",
        "        'dropout_values': dropout_values\n",
        "    },\n",
        "    'experiment_2b': {\n",
        "        'weight_decay_histories': weight_decay_histories,\n",
        "        'weight_decay_values': weight_decay_values\n",
        "    },\n",
        "}\n",
        "\n",
        "with open('HW2_A25_modern_transformer_results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "\n",
        "print(\"Results saved to 'HW2_A25_modern_transformer_results.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiBviemUx4Kc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aims",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
